{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Procesamiento de lenguaje natural"
      ],
      "metadata": {
        "id": "MrXdiguEAjnM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOjTN-c0AYz9",
        "outputId": "041ed211-972e-4e4d-ca69-bba5c1290f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "KTkypSG2Ampc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargamos recursos necesarios de NLTK\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAvUGhwRBVSb",
        "outputId": "be852619-771e-4aad-f688-f4b9ec260a5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"Hola a todos, bienvenidos al curso de Python. Hoy aprenderemos sobre procesamiento de lenguaje natural. @josecodetech\""
      ],
      "metadata": {
        "id": "bWaQcDpFBc0l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizacion de palabras\n",
        "tokens_palabras = word_tokenize(texto)\n",
        "print(\"Tokens de palabras: \", tokens_palabras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwAi-oNQBo4_",
        "outputId": "6fffd930-234a-4c42-fb4c-e858ceb2a703"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens de palabras:  ['Hola', 'a', 'todos', ',', 'bienvenidos', 'al', 'curso', 'de', 'Python', '.', 'Hoy', 'aprenderemos', 'sobre', 'procesamiento', 'de', 'lenguaje', 'natural', '.', '@', 'josecodetech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizamos oraciones\n",
        "tokens_oraciones = sent_tokenize(texto)\n",
        "print(\"Tokens de oraciones: \", tokens_oraciones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzRsort3B0al",
        "outputId": "37ba1e3e-42f6-4d6a-8967-b33c1011589f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens de oraciones:  ['Hola a todos, bienvenidos al curso de Python.', 'Hoy aprenderemos sobre procesamiento de lenguaje natural.', '@josecodetech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lematizacion"
      ],
      "metadata": {
        "id": "Ca_A58uUCJ69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "ad0Er56CCCSr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga de recursos\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plnO9GuACTgf",
        "outputId": "75cd99e8-bfc3-492b-8e01-6664e50abe47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el lematizador\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Fw3YEJKyCcGb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras de ejemplo\n",
        "palabras = [\"gatos\", \"corriendo\", \"estupendo\", \"mejor\", \"mejorado\", \"correrá\"]\n"
      ],
      "metadata": {
        "id": "6M1rfrByChLG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lematizacion de palabras\n",
        "lemas = [lemmatizer.lemmatize(palabra) for palabra in palabras]\n",
        "print(\"Lemas: \", lemas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTwcMR9UCx1D",
        "outputId": "86eaf8b6-ea96-4612-c661-c0315cb9d6b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemas:  ['gatos', 'corriendo', 'estupendo', 'mejor', 'mejorado', 'correrá']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analisis de sentimientos"
      ],
      "metadata": {
        "id": "VHBTJJvwDzgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztXLucQOC7I2",
        "outputId": "833294b9-736b-462a-8920-cefd8eff1cff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "bacstQuREF5C"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"Este curso es fantastico!, voy a compartirlo en redes con el hashtag #cursoPython de @josecodetech\""
      ],
      "metadata": {
        "id": "N3PsA095EKl7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un objeto\n",
        "blob = TextBlob(texto)"
      ],
      "metadata": {
        "id": "P6m--RBDEaea"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizamos el sentimiento\n",
        "sentimiento = blob.sentiment\n",
        "print(\"Polaridad:\",sentimiento.polarity)\n",
        "print(\"Subjetividad:\",sentimiento.subjectivity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXEub7OvEe0I",
        "outputId": "4248075e-f296-4615-f5aa-4da605f1322b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polaridad: 0.0\n",
            "Subjetividad: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio practico"
      ],
      "metadata": {
        "id": "Hxr6fx1EGvC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "eoCRrGxyGpSZ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga de recursos\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBiC-kYpG6g4",
        "outputId": "37dfb6cc-c52f-462f-9594-1c1b0682a5bc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de ejemplo\n",
        "texto = \"Hola a todos, bienvenidos al curso de Python. Hoy aprenderemos sobre procesamiento de lenguaje natural. @josecodetech. El curso es bueno, vamos a aprender mucho.\""
      ],
      "metadata": {
        "id": "-d17BjVKG_bg"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizacion de palabras y oraciones\n",
        "tokens_palabras = word_tokenize(texto)\n",
        "tokens_oraciones = sent_tokenize(texto)\n",
        "print(\"Tokens de palabras: \", tokens_palabras)\n",
        "print(\"Tokens de oraciones: \", tokens_oraciones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBO78dczHJVe",
        "outputId": "9f699981-b61f-4563-b33e-f8e7b6b2c000"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens de palabras:  ['Hola', 'a', 'todos', ',', 'bienvenidos', 'al', 'curso', 'de', 'Python', '.', 'Hoy', 'aprenderemos', 'sobre', 'procesamiento', 'de', 'lenguaje', 'natural', '.', '@', 'josecodetech', '.', 'El', 'curso', 'es', 'bueno', ',', 'vamos', 'a', 'aprender', 'mucho', '.']\n",
            "Tokens de oraciones:  ['Hola a todos, bienvenidos al curso de Python.', 'Hoy aprenderemos sobre procesamiento de lenguaje natural.', '@josecodetech.', 'El curso es bueno, vamos a aprender mucho.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lematizacion\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemas = [lemmatizer.lemmatize(palabra) for palabra in tokens_palabras]\n",
        "print(\"Lemas: \", lemas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOWwRl9pHRQ9",
        "outputId": "f3901539-ffc2-4a87-c890-1e1b5f002ebc"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemas:  ['Hola', 'a', 'todos', ',', 'bienvenidos', 'al', 'curso', 'de', 'Python', '.', 'Hoy', 'aprenderemos', 'sobre', 'procesamiento', 'de', 'lenguaje', 'natural', '.', '@', 'josecodetech', '.', 'El', 'curso', 'e', 'bueno', ',', 'vamos', 'a', 'aprender', 'mucho', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisis de sentimientos\n",
        "blob = TextBlob(texto)\n",
        "sentimiento = blob.sentiment\n",
        "print(\"Polaridad:\",sentimiento.polarity)\n",
        "print(\"Subjetividad:\",sentimiento.subjectivity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJhlFXrgHdjs",
        "outputId": "a7c63aa7-7fc1-4181-e002-a4b141070bf4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polaridad: 0.1\n",
            "Subjetividad: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PBTM_WyQHmBh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}